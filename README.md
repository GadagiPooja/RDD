# ðŸš€ PySpark RDD - Complete Guide

Welcome to the **PySpark RDD (Resilient Distributed Dataset) Guide**! This repository contains detailed explanations and hands-on examples of PySpark RDDs.

---

## ðŸ“Œ Topics Covered

âœ… **RDD Basics** - Understanding RDDs, characteristics, and advantages  
âœ… **Creating RDDs** - From Python lists, text files, and transformations  
âœ… **Transformations** - `map()`, `flatMap()`, `filter()`, `distinct()`, `union()`, `intersection()`, `cartesian()`  
âœ… **Actions** - `collect()`, `count()`, `first()`, `take()`, `reduce()`, `foreach()`  
âœ… **Caching & Persistence** - `cache()`, `persist()`, `unpersist()`  
âœ… **Key-Value RDDs** - `mapValues()`, `reduceByKey()`, `groupByKey()`, `sortByKey()`, `join()`  
âœ… **Partitions & Parallelism** - `glom()`, `repartition()`, `coalesce()`  
âœ… **RDD Lineage & DAG** - Understanding execution flow and optimization  
âœ… **Fault Tolerance in RDDs** - Lineage-based recovery, checkpointing  
âœ… **Advanced RDD Concepts** - `Broadcast Variables`, `Accumulators`, `Checkpointing`  
âœ… **Real-world Example** - Monte Carlo Pi Estimation using RDD  

---

## ðŸ”§ Prerequisites

Ensure you have **Apache Spark** and **PySpark** installed. You can install PySpark using:

```sh
pip install pyspark
